{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ewf-wfp-02-02-01 - Snow Cover Characterization Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Snow Cover Characterization Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'Snow Cover Characterization Time Series'),\n",
    "                ('abstract', 'Snow Cover Characterization Time Series'),\n",
    "                ('id', 'ewf-wfp-02-02-01')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionOfInterest = dict([('id', 'regionOfInterest'),\n",
    "                         ('value', 'POLYGON((25.0 48.0, 94.0 48.0, 94.0 23.1, 25.0 23.1, 25.0 48.0))'),\n",
    "                         ('title', 'WKT Polygon for the Region of Interest'),\n",
    "                         ('abstract', 'Set the value of WKT Polygon')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nameOfRegion = dict([('id', 'nameOfRegion'),\n",
    "                     ('value', 'CentralAsia'),\n",
    "                     ('title', 'Name of Region'),\n",
    "                     ('abstract', 'Name of the region of interest'),\n",
    "                     ('minOccurs', '1')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the MDOIS stack of products' identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('MOD10A2.A2015001.h19v04.006.2016172230552.hdf',\n",
    "                     'MOD10A2.A2015001.h19v05.006.2016172224844.hdf',\n",
    "                     'MOD10A2.A2015001.h20v04.006.2016172230600.hdf',\n",
    "                     'MOD10A2.A2015001.h20v05.006.2016172234130.hdf',\n",
    "                     'MOD10A2.A2015009.h19v04.006.2016173202655.hdf',\n",
    "                     'MOD10A2.A2015009.h19v05.006.2016173201100.hdf',\n",
    "                     'MOD10A2.A2015009.h20v04.006.2016173201300.hdf',\n",
    "                     'MOD10A2.A2015009.h20v05.006.2016173203828.hdf',\n",
    "                     'MOD10A2.A2015017.h19v04.006.2016173230827.hdf',\n",
    "                     'MOD10A2.A2015017.h19v05.006.2016173222259.hdf',\n",
    "                     'MOD10A2.A2015017.h20v04.006.2016173205042.hdf',\n",
    "                     'MOD10A2.A2015017.h20v05.006.2016173203722.hdf')\n",
    "\n",
    "input_identifiers = ('MOD10A2.A2015217.h19v04.006.2016181040203.hdf','MOD10A2.A2015217.h19v05.006.2016181041147.hdf','MOD10A2.A2015217.h20v04.006.2016181040703.hdf','MOD10A2.A2015217.h20v05.006.2016181041352.hdf','MOD10A2.A2015225.h19v04.006.2016181061932.hdf','MOD10A2.A2015225.h19v05.006.2016181061952.hdf','MOD10A2.A2015225.h20v04.006.2016181061951.hdf','MOD10A2.A2015225.h20v05.006.2016181061109.hdf','MOD10A2.A2015233.h19v04.006.2016181065423.hdf','MOD10A2.A2015233.h19v05.006.2016181071440.hdf','MOD10A2.A2015233.h20v04.006.2016181070735.hdf','MOD10A2.A2015233.h20v05.006.2016181065807.hdf','MOD10A2.A2015241.h19v04.006.2016181062033.hdf','MOD10A2.A2015241.h19v05.006.2016181051646.hdf','MOD10A2.A2015241.h20v04.006.2016181053544.hdf','MOD10A2.A2015241.h20v05.006.2016181053542.hdf','MOD10A2.A2015249.h19v04.006.2016181080505.hdf','MOD10A2.A2015249.h19v05.006.2016181070522.hdf','MOD10A2.A2015249.h20v04.006.2016181070456.hdf','MOD10A2.A2015249.h20v05.006.2016181071344.hdf','MOD10A2.A2015257.h19v04.006.2016181065140.hdf','MOD10A2.A2015257.h19v05.006.2016181064608.hdf','MOD10A2.A2015257.h20v04.006.2016181070354.hdf','MOD10A2.A2015257.h20v05.006.2016181064104.hdf','MOD10A2.A2015265.h19v04.006.2016181065815.hdf','MOD10A2.A2015265.h19v05.006.2016181064618.hdf','MOD10A2.A2015265.h20v04.006.2016181072259.hdf','MOD10A2.A2015265.h20v05.006.2016181070932.hdf','MOD10A2.A2015273.h19v04.006.2016181062047.hdf','MOD10A2.A2015273.h19v05.006.2016181062026.hdf','MOD10A2.A2015273.h20v04.006.2016181062930.hdf','MOD10A2.A2015273.h20v05.006.2016181061637.hdf','MOD10A2.A2015281.h19v04.006.2016181201907.hdf','MOD10A2.A2015281.h19v05.006.2016181202801.hdf','MOD10A2.A2015281.h20v04.006.2016181201807.hdf','MOD10A2.A2015281.h20v05.006.2016181202922.hdf','MOD10A2.A2015289.h19v04.006.2016182032251.hdf','MOD10A2.A2015289.h19v05.006.2016182030630.hdf','MOD10A2.A2015289.h20v04.006.2016182032143.hdf','MOD10A2.A2015289.h20v05.006.2016182031542.hdf','MOD10A2.A2015297.h19v04.006.2016182032350.hdf','MOD10A2.A2015297.h19v05.006.2016182031829.hdf','MOD10A2.A2015297.h20v04.006.2016182032348.hdf','MOD10A2.A2015297.h20v05.006.2016182024408.hdf','MOD10A2.A2015305.h19v04.006.2016182033801.hdf','MOD10A2.A2015305.h19v05.006.2016182033426.hdf','MOD10A2.A2015305.h20v04.006.2016182034126.hdf','MOD10A2.A2015305.h20v05.006.2016182034127.hdf','MOD10A2.A2015313.h19v04.006.2016182040147.hdf','MOD10A2.A2015313.h19v05.006.2016182040153.hdf','MOD10A2.A2015313.h20v04.006.2016182033808.hdf','MOD10A2.A2015313.h20v05.006.2016182034309.hdf','MOD10A2.A2015321.h19v04.006.2016182042502.hdf','MOD10A2.A2015321.h19v05.006.2016182042459.hdf','MOD10A2.A2015321.h20v04.006.2016182042501.hdf','MOD10A2.A2015321.h20v05.006.2016182042344.hdf','MOD10A2.A2015329.h19v04.006.2016182041522.hdf','MOD10A2.A2015329.h19v05.006.2016182040439.hdf','MOD10A2.A2015329.h20v04.006.2016182043811.hdf','MOD10A2.A2015329.h20v05.006.2016182042612.hdf','MOD10A2.A2015337.h19v04.006.2016182044041.hdf','MOD10A2.A2015337.h19v05.006.2016182042222.hdf','MOD10A2.A2015337.h20v04.006.2016182042340.hdf','MOD10A2.A2015337.h20v05.006.2016182041747.hdf','MOD10A2.A2015345.h19v04.006.2016182155822.hdf','MOD10A2.A2015345.h19v05.006.2016182155815.hdf','MOD10A2.A2015345.h20v04.006.2016182160042.hdf','MOD10A2.A2015345.h20v05.006.2016182155452.hdf','MOD10A2.A2015353.h19v04.006.2016182205041.hdf','MOD10A2.A2015353.h19v05.006.2016182205255.hdf','MOD10A2.A2015353.h20v04.006.2016182204052.hdf','MOD10A2.A2015353.h20v05.006.2016182204052.hdf','MOD10A2.A2015361.h19v04.006.2016183124258.hdf','MOD10A2.A2015361.h19v05.006.2016183123821.hdf','MOD10A2.A2015361.h20v04.006.2016183124250.hdf','MOD10A2.A2015361.h20v05.006.2016183124103.hdf','MOD10A2.A2016001.h19v04.006.2016183134249.hdf','MOD10A2.A2016001.h19v05.006.2016183134250.hdf','MOD10A2.A2016001.h20v04.006.2016183134934.hdf','MOD10A2.A2016001.h20v05.006.2016183134219.hdf','MOD10A2.A2016009.h19v04.006.2016182225710.hdf','MOD10A2.A2016009.h19v05.006.2016182225713.hdf','MOD10A2.A2016009.h20v04.006.2016182230041.hdf','MOD10A2.A2016009.h20v05.006.2016182230038.hdf','MOD10A2.A2016017.h19v04.006.2016026072835.hdf','MOD10A2.A2016017.h19v05.006.2016026072809.hdf','MOD10A2.A2016017.h20v04.006.2016026072827.hdf','MOD10A2.A2016017.h20v05.006.2016026072830.hdf','MOD10A2.A2016025.h19v04.006.2016035164135.hdf','MOD10A2.A2016025.h19v05.006.2016035161920.hdf','MOD10A2.A2016025.h20v04.006.2016035161812.hdf','MOD10A2.A2016025.h20v05.006.2016035162249.hdf','MOD10A2.A2016033.h19v04.006.2016043141801.hdf','MOD10A2.A2016033.h19v05.006.2016043142308.hdf','MOD10A2.A2016033.h20v04.006.2016043141936.hdf','MOD10A2.A2016033.h20v05.006.2016043141732.hdf','MOD10A2.A2016041.h19v04.006.2016050071609.hdf','MOD10A2.A2016041.h19v05.006.2016050071329.hdf','MOD10A2.A2016041.h20v04.006.2016050072409.hdf','MOD10A2.A2016041.h20v05.006.2016050072227.hdf','MOD10A2.A2016065.h19v04.006.2016110192134.hdf','MOD10A2.A2016065.h19v05.006.2016110191744.hdf','MOD10A2.A2016065.h20v04.006.2016110192217.hdf','MOD10A2.A2016065.h20v05.006.2016110191835.hdf','MOD10A2.A2016073.h19v04.006.2016110194154.hdf','MOD10A2.A2016073.h19v05.006.2016110193845.hdf','MOD10A2.A2016073.h20v04.006.2016110194056.hdf','MOD10A2.A2016073.h20v05.006.2016110193919.hdf','MOD10A2.A2016081.h19v04.006.2016110200007.hdf','MOD10A2.A2016081.h19v05.006.2016110195736.hdf','MOD10A2.A2016081.h20v04.006.2016110200229.hdf','MOD10A2.A2016081.h20v05.006.2016110195910.hdf','MOD10A2.A2016089.h19v04.006.2016110203223.hdf','MOD10A2.A2016089.h19v05.006.2016110202008.hdf','MOD10A2.A2016089.h20v04.006.2016110205818.hdf','MOD10A2.A2016089.h20v05.006.2016110204545.hdf','MOD10A2.A2016097.h19v04.006.2016106221629.hdf','MOD10A2.A2016097.h19v05.006.2016106221517.hdf','MOD10A2.A2016097.h20v04.006.2016106221639.hdf','MOD10A2.A2016097.h20v05.006.2016106221302.hdf','MOD10A2.A2016105.h19v04.006.2016114082452.hdf','MOD10A2.A2016105.h19v05.006.2016114082255.hdf','MOD10A2.A2016105.h20v04.006.2016114075955.hdf','MOD10A2.A2016105.h20v05.006.2016114074736.hdf','MOD10A2.A2016113.h19v04.006.2016123132422.hdf','MOD10A2.A2016113.h19v05.006.2016123133639.hdf','MOD10A2.A2016113.h20v04.006.2016123132424.hdf','MOD10A2.A2016113.h20v05.006.2016123132417.hdf','MOD10A2.A2016121.h19v04.006.2016130154408.hdf','MOD10A2.A2016121.h19v05.006.2016130152344.hdf','MOD10A2.A2016121.h20v04.006.2016130151711.hdf','MOD10A2.A2016121.h20v05.006.2016130152048.hdf','MOD10A2.A2016129.h19v04.006.2016140154151.hdf','MOD10A2.A2016129.h19v05.006.2016140153820.hdf','MOD10A2.A2016129.h20v04.006.2016140154121.hdf','MOD10A2.A2016129.h20v05.006.2016140153448.hdf','MOD10A2.A2016137.h19v04.006.2016147150819.hdf','MOD10A2.A2016137.h19v05.006.2016147151208.hdf','MOD10A2.A2016137.h20v04.006.2016147144543.hdf','MOD10A2.A2016137.h20v05.006.2016147145117.hdf','MOD10A2.A2016145.h19v04.006.2016155181856.hdf','MOD10A2.A2016145.h19v05.006.2016155181506.hdf','MOD10A2.A2016145.h20v04.006.2016155181651.hdf','MOD10A2.A2016145.h20v05.006.2016155181433.hdf','MOD10A2.A2016153.h19v04.006.2016166184550.hdf','MOD10A2.A2016153.h19v05.006.2016166184317.hdf','MOD10A2.A2016153.h20v04.006.2016166184434.hdf','MOD10A2.A2016153.h20v05.006.2016166184550.hdf','MOD10A2.A2016161.h19v04.006.2016170072859.hdf','MOD10A2.A2016161.h19v05.006.2016170072607.hdf','MOD10A2.A2016161.h20v04.006.2016170073849.hdf','MOD10A2.A2016161.h20v05.006.2016170073611.hdf','MOD10A2.A2016169.h19v04.006.2016184041911.hdf','MOD10A2.A2016169.h19v05.006.2016184040300.hdf','MOD10A2.A2016169.h20v04.006.2016184041926.hdf','MOD10A2.A2016169.h20v05.006.2016184041852.hdf','MOD10A2.A2016177.h19v04.006.2016188012837.hdf','MOD10A2.A2016177.h19v05.006.2016188012519.hdf','MOD10A2.A2016177.h20v04.006.2016188012552.hdf','MOD10A2.A2016177.h20v05.006.2016188012443.hdf','MOD10A2.A2016185.h19v04.006.2016194193853.hdf','MOD10A2.A2016185.h19v05.006.2016194193610.hdf','MOD10A2.A2016185.h20v04.006.2016194194258.hdf','MOD10A2.A2016185.h20v05.006.2016194194306.hdf','MOD10A2.A2016193.h19v04.006.2016202083932.hdf','MOD10A2.A2016193.h19v05.006.2016202085128.hdf','MOD10A2.A2016193.h20v04.006.2016202083722.hdf','MOD10A2.A2016193.h20v05.006.2016202083631.hdf','MOD10A2.A2016201.h19v04.006.2016215123536.hdf','MOD10A2.A2016201.h19v05.006.2016215123748.hdf','MOD10A2.A2016201.h20v04.006.2016215123826.hdf','MOD10A2.A2016201.h20v05.006.2016215123656.hdf','MOD10A2.A2016209.h19v04.006.2016222123114.hdf','MOD10A2.A2016209.h19v05.006.2016222122928.hdf','MOD10A2.A2016209.h20v04.006.2016222123118.hdf','MOD10A2.A2016209.h20v05.006.2016222122820.hdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the MODIS stack catalogue references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = tuple(['https://catalog.terradue.com/modis/search?uid={0}'.format(pid) for pid in input_identifiers])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/data/MOD10A2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aux folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_folder = 'temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import sys\n",
    "import string\n",
    "import numpy as np\n",
    "from osgeo import gdal, ogr, osr\n",
    "from shapely.wkt import loads\n",
    "\n",
    "import math\n",
    "\n",
    "import datetime\n",
    "\n",
    "import pdb\n",
    "\n",
    "from convertmodis_gdal import createMosaicGDAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If True loads all imagens in one var (consumes a lot of memory!!)\n",
    "# If False loads image when it needs (takes a lot of time!!)\n",
    "load_all_data = False\n",
    "\n",
    "# plots and etc.\n",
    "check_results = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove contents of a given folder\n",
    "# used to clean a temporary folder\n",
    "def rm_cfolder(folder):\n",
    "    #folder = '/path/to/folder'\n",
    "    for the_file in os.listdir(folder):\n",
    "        file_path = os.path.join(folder, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path): shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "\n",
    "def get_metadata(filepath):\n",
    "    ds = gdal.Open(filepath)\n",
    "    projection = ds.GetProjection()\n",
    "    geotransform = ds.GetGeoTransform()\n",
    "    no_data_value = ds.GetRasterBand(1).GetNoDataValue()\n",
    "    data_type = ds.GetRasterBand(1).DataType\n",
    "    return projection, geotransform, no_data_value, data_type\n",
    "\n",
    "def get_matrix_list(image_list):\n",
    "    mat_list = []\n",
    "    for img in image_list:\n",
    "        dataset = gdal.Open(img)\n",
    "        product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "        mat_list.append(product_array)\n",
    "        dataset = None\n",
    "    return mat_list\n",
    "\n",
    "def load_img_to_matrix (img_path):\n",
    "    \n",
    "    dataset = gdal.Open(img_path)\n",
    "    product_array = dataset.GetRasterBand(1).ReadAsArray()\n",
    "    return product_array\n",
    "\n",
    "\n",
    "# computes matrix with the number of snow days\n",
    "# used to compute 2) Count of number of snow days during the season\n",
    "def get_snow_ndays (matrix_list):\n",
    "    \n",
    "    # Receives a list of strings containing the paths of the images\n",
    "    # or\n",
    "    # Receives a list of numpy arrays with the images loaded\n",
    "    \n",
    "    if isinstance(matrix_list[0], str):\n",
    "        snow_ndays = np.full_like(load_img_to_matrix(matrix_list[0]), 0)\n",
    "    else:\n",
    "        snow_ndays = np.full_like(matrix_list[0], 0)\n",
    "    \n",
    "    \n",
    "    for m in matrix_list:\n",
    "\n",
    "        # NEW\n",
    "        if isinstance(m, str):\n",
    "            m = load_img_to_matrix (m)\n",
    "\n",
    "        # convert each element to its binary sequence and counts the number os 1s\n",
    "        snow_ndays_counter = np.vectorize(lambda m: format(m, 'b').count('1'))\n",
    "        \n",
    "        snow_ndays = snow_ndays + snow_ndays_counter(m)\n",
    "\n",
    "    return snow_ndays\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# given a string of 0s and 1s\n",
    "# returns: num_of_1s - last number of consecutive numbers of 1s\n",
    "#          max_num_of_1s_so_far - last max number of consecutive numbers of 1s\n",
    "#          last_car - the last character ('0' or '1')\n",
    "# it also recives those variables as input in order to apply it to a sequence os strings\n",
    "# used to compute 3) Count of number of consecutive snow cover days\n",
    "def count_of_major_consecutive_sc_days(sr, num_of_1s = 0, max_num_of_1s_so_far = 0, last_car = '0'):\n",
    "    \n",
    "    if isinstance(sr, str) and len(sr) == 8:\n",
    "        pass\n",
    "    else:\n",
    "        # convert to binary sequence os 0s and 1s\n",
    "        # fill with 0 to the extent of 8 chars\n",
    "        # reverse order (because modis stores info in reverse order)\n",
    "        sr = format(sr, 'b').zfill(8)[::-1]\n",
    "    \n",
    "    for c in sr:\n",
    "        \n",
    "        if c == '1' and last_car == '1':\n",
    "            num_of_1s = num_of_1s + 1\n",
    "            \n",
    "        elif c == '1' and last_car == '0':\n",
    "            \n",
    "            if num_of_1s > max_num_of_1s_so_far:\n",
    "                max_num_of_1s_so_far = num_of_1s\n",
    "            \n",
    "            num_of_1s = 1\n",
    "            \n",
    "        last_car = c\n",
    "        if num_of_1s > max_num_of_1s_so_far:\n",
    "            max_num_of_1s_so_far = num_of_1s\n",
    "            \n",
    "    return num_of_1s, max_num_of_1s_so_far, last_car\n",
    "\n",
    "# Apply count_of_major_consecutive_sc_days to a list os matrices\n",
    "# os sequences os 0s and 1s\n",
    "# used to compute 3) Count of number of consecutive snow cover days\n",
    "def get_max_sc_consecutive_ndays (matrix_list):\n",
    "    \n",
    "\n",
    "    num_of_1s = np.zeros(matrix_list[0].shape)\n",
    "    max_num_of_1s_so_far = np.zeros(matrix_list[0].shape)  \n",
    "    last_car = np.full(matrix_list[0].shape, ['0'],dtype=str)\n",
    "    \n",
    "    major_consecutive_sc_days_counter = np.vectorize(count_of_major_consecutive_sc_days)\n",
    "    \n",
    "    for m in matrix_list:\n",
    "        num_of_1s, max_num_of_1s_so_far, last_car = major_consecutive_sc_days_counter(m, num_of_1s, max_num_of_1s_so_far, last_car)\n",
    "    \n",
    "    return max_num_of_1s_so_far\n",
    "\n",
    "\n",
    "# find idexes of 1st image and 1st '1' in binary sequence\n",
    "# input:\n",
    "# sr - string of current binary sequence\n",
    "# pos_current_img - index of current img\n",
    "# pos_img1 - index of 1st img with snow\n",
    "# pos_img2 - index of 2nd img with snow\n",
    "# pos_1st_snow - pos [0-7] of 1st '1' in the binary sequence\n",
    "#\n",
    "# -1 used as nodata\n",
    "#\n",
    "# used to compute 4) Start and end date of snow cover season\n",
    "def find_start_day_snow_season_idx(sr, pos_current_img, pos_img1 = -1, pos_img2 = -1, pos_1st_snow = -1):\n",
    "    \n",
    "    if isinstance(sr, str) and len(sr) == 8:\n",
    "        pass\n",
    "    else:\n",
    "        # convert to binary sequence os 0s and 1s\n",
    "        # fill with 0 to the extent of 8 chars\n",
    "        # reverse order (because modis stores info in reverse order)\n",
    "        sr = format(sr, 'b') #.zfill(8)[::-1]\n",
    "        \n",
    "    if '1' in sr: # if sr contains at least one 1\n",
    "        \n",
    "        if pos_img1 == -1:\n",
    "            pos_img1 = pos_current_img\n",
    "            pos_1st_snow = sr.zfill(8)[::-1].find('1')\n",
    "        else:\n",
    "            if pos_img2 == -1:\n",
    "                pos_img2 = pos_current_img\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    else:\n",
    "        if pos_img1 == -1:\n",
    "            pass\n",
    "        else:\n",
    "            pos_img1 = -1\n",
    "            pos_1st_snow = -1\n",
    "            \n",
    "    return pos_img1, pos_img2, pos_1st_snow\n",
    "\n",
    "    \n",
    "\n",
    "# Apply find_start_day_snow_season_idx to a list of snow cover images\n",
    "# used to compute 4) Start and end date of snow cover season\n",
    "def get_start_day_snow_season (matrix_list, pos_img1 = None, pos_img2 = None, pos_1st_snow = None):\n",
    " \n",
    "    if pos_img1 is None:\n",
    "        pos_img1 = np.ones(matrix_list[0].shape) * -1\n",
    "    if pos_img2 is None:\n",
    "        pos_img2 = np.ones(matrix_list[0].shape) * -1\n",
    "    if pos_1st_snow is None:\n",
    "        pos_1st_snow = np.ones(matrix_list[0].shape) * -1\n",
    "    \n",
    "    start_day_snow_season_finder = np.vectorize(find_start_day_snow_season_idx)\n",
    "    \n",
    "    for idxsa in range(len(matrix_list)):\n",
    "        \n",
    "        pos_img1, pos_img2, pos_1st_snow = start_day_snow_season_finder(matrix_list[idxsa], idxsa, pos_img1, pos_img2, pos_1st_snow)\n",
    "    \n",
    "    return pos_img1, pos_1st_snow\n",
    "\n",
    "\n",
    "\n",
    "def find_end_day_snow_season_idx(sr, pos_current_img, pos_img1 = -1, pos_img2 = -1, pos_1st_snow = -1):\n",
    "    \n",
    "    if isinstance(sr, str) and len(sr) == 8:\n",
    "        pass\n",
    "    else:\n",
    "        # convert to binary sequence os 0s and 1s\n",
    "        # fill with 0 to the extent of 8 chars\n",
    "        # reverse order (because modis stores info in reverse order)\n",
    "        sr = format(sr, 'b') #.zfill(8)[::-1]\n",
    "        \n",
    "    if '1' in sr: # if sr contains at least one 1\n",
    "        \n",
    "        if pos_img1 == -1:\n",
    "            pass\n",
    "        else:\n",
    "            pos_img1 = -1\n",
    "            pos_1st_snow = -1      \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if pos_img1 == -1:\n",
    "            pos_img1 = pos_current_img\n",
    "            #pos_1st_snow = sr.zfill(8)[::-1].find('1')\n",
    "        else:\n",
    "            if pos_img2 == -1:\n",
    "                pos_img2 = pos_current_img\n",
    "                pos_1st_snow = 7\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "    return pos_img1, pos_img2, pos_1st_snow\n",
    "\n",
    "\n",
    "\n",
    "def get_end_day_snow_season (matrix_list, pos_img1 = None, pos_img2 = None, pos_1st_snow = None):\n",
    "\n",
    "    \n",
    "    if pos_img1 is None:\n",
    "        pos_img1 = np.ones(matrix_list[0].shape) * -1\n",
    "    if pos_img2 is None:\n",
    "        pos_img2 = np.ones(matrix_list[0].shape) * -1\n",
    "    if pos_1st_snow is None:\n",
    "        pos_1st_snow = np.ones(matrix_list[0].shape) * -1\n",
    "\n",
    "    \n",
    "    end_day_snow_season_finder = np.vectorize(find_end_day_snow_season_idx)\n",
    "    \n",
    "    for idxsa in range(len(matrix_list)):\n",
    "        \n",
    "        pos_img1, pos_img2, pos_1st_snow = end_day_snow_season_finder(matrix_list[idxsa], idxsa, pos_img1, pos_img2, pos_1st_snow)\n",
    "    \n",
    "    return pos_img1, pos_1st_snow\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#(COS DOY) is the cosine of the Julian date transformed to radians or degrees;\n",
    "# that is, = cos (2 \\pi t / 365) or cos(360º t / 365) and t is the Julian date of the valid time (the Julian date for January 1st is 1, and for October 31st it is 304)\n",
    "# From Statistical Methods in the Atmospheric Sciences by Daniel S. Wilks\n",
    "# used to compute 4) Start and end date of snow cover season\n",
    "def date2COSDOY (date):\n",
    "    # datetime.datetime(2019,12,30)\n",
    "    return math.cos(2 * math.pi * date.timetuple().tm_yday / 365)\n",
    "\n",
    "# given a list of dates,\n",
    "# the index in that list and the index in the eight day sequence\n",
    "# returns cos_doy\n",
    "# used to compute 4) Start and end date of snow cover season\n",
    "def indexes_to_cosdoy (dates, img_idx, eight_day_idx):\n",
    "    \n",
    "    if img_idx == -1:\n",
    "        return -999\n",
    "    \n",
    "    date = dates[img_idx] + datetime.timedelta(days=eight_day_idx)\n",
    "    return date2COSDOY(date)\n",
    "\n",
    "\n",
    "# Computes cos_doy for a given image index and binary position\n",
    "# py_dates - ordered list of date in python datetime format\n",
    "# pos_img - img idx\n",
    "# pos_8_im - pos in binary sequence\n",
    "# used to compute 4) Start and end date of snow cover season\n",
    "def get_cos_doy_snow_season(py_dates, pos_im, pos_8_im):\n",
    "    cos_doy = np.zeros(pos_im.shape)\n",
    "    ni,nj = pos_im.shape\n",
    "    for i in range(ni):\n",
    "        for j in range(nj):\n",
    "            cos_doy[i,j] = indexes_to_cosdoy (py_dates, pos_im[i,j], pos_8_im[i,j])\n",
    "        \n",
    "    return cos_doy\n",
    "\n",
    "\n",
    "def write_output_image(filepath, output_matrix, image_format, data_format, mask=None, output_projection=None, output_geotransform=None, no_data_value=None):\n",
    "    \n",
    "    driver = gdal.GetDriverByName(image_format)\n",
    "    out_rows = np.size(output_matrix, 0)\n",
    "    out_columns = np.size(output_matrix, 1)\n",
    "    \n",
    "    \n",
    "    if mask is not None and mask is not 0:\n",
    "        # TODO: check if output folder exists\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 2, data_format)\n",
    "        mask_band = output.GetRasterBand(2)\n",
    "        mask_band.WriteArray(mask)\n",
    "        if no_data_value is not None:\n",
    "            output_matrix[mask > 0] = no_data_value\n",
    "    else:\n",
    "        output = driver.Create(filepath, out_columns, out_rows, 1, data_format)\n",
    "    \n",
    "    if output_projection is not None:\n",
    "        output.SetProjection(output_projection)\n",
    "    if output_geotransform is not None:\n",
    "        output.SetGeoTransform(output_geotransform)\n",
    "    \n",
    "    raster_band = output.GetRasterBand(1)\n",
    "    if no_data_value is not None:\n",
    "        raster_band.SetNoDataValue(no_data_value)\n",
    "    raster_band.WriteArray(output_matrix)\n",
    "    \n",
    "    gdal.Warp(filepath, output, format=\"GTiff\", outputBoundsSRS='EPSG:4326', xRes=output_geotransform[1], yRes=-output_geotransform[5], targetAlignedPixels=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teste\n",
      "new cenas\n",
      "(2, 3, '1')\n",
      "(32, 32, '1')\n",
      "now with matrices\n",
      "[array([['10111011', '11111111', '11100001'],\n",
      "       ['10010000', '00011100', '11100000']], dtype='|S8'), array([['10111011', '11111111', '11100001'],\n",
      "       ['10010000', '00011100', '11100000']], dtype='|S8')]\n",
      "[[ 3 16  4]\n",
      " [ 1  3  3]]\n",
      "(3, 4, 4)\n",
      "[[0 0 1]\n",
      " [0 3 0]]\n",
      "[[0 0 0]\n",
      " [4 2 5]]\n",
      "(8, 9, 7)\n",
      "[[-1. -1. -1.]\n",
      " [-1.  3.  3.]]\n",
      "[[-1. -1. -1.]\n",
      " [-1. -1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "if check_results:\n",
    "\n",
    "    print('teste')\n",
    "    snow_array = ['10111011', '11111111', '11100001', '10010000', '00011100', '11100011']\n",
    "\n",
    "    snow_array1 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '00011100', '11100000']])\n",
    "\n",
    "    snow_array2 = np.array([['10111011', '11111111', '11100001'],\n",
    "                           ['10010000', '00011100', '11100000']])\n",
    "\n",
    "    snow_matrix_list = [snow_array1]\n",
    "    snow_matrix_list.append(snow_array2)\n",
    "\n",
    "    '''\n",
    "    n_ant_snow = 0\n",
    "    n_cons = 0\n",
    "    for sr in snow_array:\n",
    "        n_ant_snow, n_cons = count_consecutive_sc_days(sr, n_ant_snow, n_cons, min_sc_days = 2)\n",
    "        #print(n_cons)\n",
    "\n",
    "    if n_ant_snow >= 2:\n",
    "        n_cons = n_cons + 1\n",
    "\n",
    "    print(snow_array)\n",
    "    print(n_cons)\n",
    "    '''\n",
    "\n",
    "    print('new cenas')\n",
    "    print(count_of_major_consecutive_sc_days(snow_array[0]))\n",
    "\n",
    "    num_of_1s = 0\n",
    "    max_num_of_1s_so_far = 0\n",
    "    last_car = '0'\n",
    "    for s in ['11111111', '11111111' , '11111111' , '11111111']:\n",
    "    \n",
    "        num_of_1s, max_num_of_1s_so_far, last_car = count_of_major_consecutive_sc_days(s, num_of_1s, max_num_of_1s_so_far, last_car)\n",
    "    \n",
    "    print(num_of_1s, max_num_of_1s_so_far, last_car)\n",
    "\n",
    "\n",
    "\n",
    "    print('now with matrices')\n",
    "\n",
    "    print(snow_matrix_list)\n",
    "    c = get_max_sc_consecutive_ndays (snow_matrix_list)\n",
    "\n",
    "    print(c)\n",
    "    \n",
    "    \n",
    "    # about start date snow\n",
    "    \n",
    "    \n",
    "    \n",
    "    snow_array = ['10111011', '11111111', '11100001', '10010000', '00011100', '11100011']\n",
    "    snow_array = ['00000000', '00010000', '00000000', '10010000', '00011100', '11100011']\n",
    "\n",
    "    pos_img1 = -1\n",
    "    pos_img2 = -1\n",
    "    pos_1st_snow = -1\n",
    "\n",
    "    for idxsa in range(len(snow_array)):\n",
    "    \n",
    "        pos_img1, pos_img2, pos_1st_snow = find_start_day_snow_season_idx(snow_array[idxsa], idxsa, pos_img1, pos_img2, pos_1st_snow)\n",
    "    \n",
    "    print(pos_img1, pos_img2, pos_1st_snow)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    snow_array1 = np.array([['10111011', '11111111', '00000000'],\n",
    "                            ['10010000', '00000000', '11100000']])\n",
    "\n",
    "    snow_array2 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '00000100', '11100000']])\n",
    "    \n",
    "    snow_array3 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '00000000', '11100000']])\n",
    "\n",
    "    snow_array4 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '00011100', '11100000']])\n",
    "\n",
    "    snow_array4 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '00011100', '11100000']])\n",
    "\n",
    "    snow_matrix_list = [snow_array1]\n",
    "    snow_matrix_list.append(snow_array2)\n",
    "    snow_matrix_list.append(snow_array3)\n",
    "    snow_matrix_list.append(snow_array4)\n",
    "    \n",
    "\n",
    "    pos_im, pos_8 = get_start_day_snow_season (snow_matrix_list)\n",
    "\n",
    "    print(pos_im)\n",
    "    print(pos_8)\n",
    "    \n",
    "   \n",
    "\n",
    "    snow_array = ['10111011', '11111111', '11100001', '10010000', '00011100', '11100011']\n",
    "    snow_array = ['00000000', '00010000', '00000000', '10010000', '00011100', '11100011', '00000000', '11100011', '00000000', '00000000']\n",
    "\n",
    "    pos_img1 = -1\n",
    "    pos_img2 = -1\n",
    "    pos_1st_snow = -1\n",
    "\n",
    "    for idxsa in range(len(snow_array)):\n",
    "        pos_img1, pos_img2, pos_1st_snow = find_end_day_snow_season_idx(snow_array[idxsa], idxsa, pos_img1, pos_img2, pos_1st_snow)\n",
    "\n",
    "    print(pos_img1, pos_img2, pos_1st_snow)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    snow_array1 = np.array([['10111011', '11111111', '00000000'],\n",
    "                            ['10010000', '11111111', '11100000']])\n",
    "\n",
    "    snow_array2 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '00000000', '11100000']])\n",
    "    \n",
    "    snow_array3 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '11100000', '11100000']])\n",
    "\n",
    "    snow_array4 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '00000000', '00000000']])\n",
    "\n",
    "    snow_array4 = np.array([['10111011', '11111111', '11100001'],\n",
    "                            ['10010000', '00000000', '00000000']])\n",
    "\n",
    "    snow_matrix_list = [snow_array1]\n",
    "    snow_matrix_list.append(snow_array2)\n",
    "    snow_matrix_list.append(snow_array3)\n",
    "    snow_matrix_list.append(snow_array4)\n",
    "    \n",
    "\n",
    "    pos_im, pos_8 = get_end_day_snow_season (snow_matrix_list)\n",
    "\n",
    "    print(pos_im)\n",
    "    print(pos_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create folders\n",
    "#if not os.path.isdir(data_path):\n",
    "#    os.mkdir(data_path)\n",
    "\n",
    "if len(output_folder) > 0:\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.mkdir(output_folder)\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Group identifiers by date for the mosaicking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-10-16\n",
      "['MOD10A2.A2015289.h19v04.006.2016182032251.hdf', 'MOD10A2.A2015289.h19v05.006.2016182030630.hdf', 'MOD10A2.A2015289.h20v04.006.2016182032143.hdf', 'MOD10A2.A2015289.h20v05.006.2016182031542.hdf']\n",
      "2016-05-08\n",
      "['MOD10A2.A2016129.h19v04.006.2016140154151.hdf', 'MOD10A2.A2016129.h19v05.006.2016140153820.hdf', 'MOD10A2.A2016129.h20v04.006.2016140154121.hdf', 'MOD10A2.A2016129.h20v05.006.2016140153448.hdf']\n",
      "2015-08-29\n",
      "['MOD10A2.A2015241.h19v04.006.2016181062033.hdf', 'MOD10A2.A2015241.h19v05.006.2016181051646.hdf', 'MOD10A2.A2015241.h20v04.006.2016181053544.hdf', 'MOD10A2.A2015241.h20v05.006.2016181053542.hdf']\n",
      "2016-07-19\n",
      "['MOD10A2.A2016201.h19v04.006.2016215123536.hdf', 'MOD10A2.A2016201.h19v05.006.2016215123748.hdf', 'MOD10A2.A2016201.h20v04.006.2016215123826.hdf', 'MOD10A2.A2016201.h20v05.006.2016215123656.hdf']\n",
      "2015-08-05\n",
      "['MOD10A2.A2015217.h19v04.006.2016181040203.hdf', 'MOD10A2.A2015217.h19v05.006.2016181041147.hdf', 'MOD10A2.A2015217.h20v04.006.2016181040703.hdf', 'MOD10A2.A2015217.h20v05.006.2016181041352.hdf']\n",
      "2015-08-21\n",
      "['MOD10A2.A2015233.h19v04.006.2016181065423.hdf', 'MOD10A2.A2015233.h19v05.006.2016181071440.hdf', 'MOD10A2.A2015233.h20v04.006.2016181070735.hdf', 'MOD10A2.A2015233.h20v05.006.2016181065807.hdf']\n",
      "2016-04-06\n",
      "['MOD10A2.A2016097.h19v04.006.2016106221629.hdf', 'MOD10A2.A2016097.h19v05.006.2016106221517.hdf', 'MOD10A2.A2016097.h20v04.006.2016106221639.hdf', 'MOD10A2.A2016097.h20v05.006.2016106221302.hdf']\n",
      "2016-04-22\n",
      "['MOD10A2.A2016113.h19v04.006.2016123132422.hdf', 'MOD10A2.A2016113.h19v05.006.2016123133639.hdf', 'MOD10A2.A2016113.h20v04.006.2016123132424.hdf', 'MOD10A2.A2016113.h20v05.006.2016123132417.hdf']\n",
      "2015-11-17\n",
      "['MOD10A2.A2015321.h19v04.006.2016182042502.hdf', 'MOD10A2.A2015321.h19v05.006.2016182042459.hdf', 'MOD10A2.A2015321.h20v04.006.2016182042501.hdf', 'MOD10A2.A2015321.h20v05.006.2016182042344.hdf']\n",
      "2016-06-25\n",
      "['MOD10A2.A2016177.h19v04.006.2016188012837.hdf', 'MOD10A2.A2016177.h19v05.006.2016188012519.hdf', 'MOD10A2.A2016177.h20v04.006.2016188012552.hdf', 'MOD10A2.A2016177.h20v05.006.2016188012443.hdf']\n",
      "2016-06-09\n",
      "['MOD10A2.A2016161.h19v04.006.2016170072859.hdf', 'MOD10A2.A2016161.h19v05.006.2016170072607.hdf', 'MOD10A2.A2016161.h20v04.006.2016170073849.hdf', 'MOD10A2.A2016161.h20v05.006.2016170073611.hdf']\n",
      "2016-01-01\n",
      "['MOD10A2.A2016001.h19v04.006.2016183134249.hdf', 'MOD10A2.A2016001.h19v05.006.2016183134250.hdf', 'MOD10A2.A2016001.h20v04.006.2016183134934.hdf', 'MOD10A2.A2016001.h20v05.006.2016183134219.hdf']\n",
      "2016-01-25\n",
      "['MOD10A2.A2016025.h19v04.006.2016035164135.hdf', 'MOD10A2.A2016025.h19v05.006.2016035161920.hdf', 'MOD10A2.A2016025.h20v04.006.2016035161812.hdf', 'MOD10A2.A2016025.h20v05.006.2016035162249.hdf']\n",
      "2015-12-03\n",
      "['MOD10A2.A2015337.h19v04.006.2016182044041.hdf', 'MOD10A2.A2015337.h19v05.006.2016182042222.hdf', 'MOD10A2.A2015337.h20v04.006.2016182042340.hdf', 'MOD10A2.A2015337.h20v05.006.2016182041747.hdf']\n",
      "2016-06-01\n",
      "['MOD10A2.A2016153.h19v04.006.2016166184550.hdf', 'MOD10A2.A2016153.h19v05.006.2016166184317.hdf', 'MOD10A2.A2016153.h20v04.006.2016166184434.hdf', 'MOD10A2.A2016153.h20v05.006.2016166184550.hdf']\n",
      "2016-01-09\n",
      "['MOD10A2.A2016009.h19v04.006.2016182225710.hdf', 'MOD10A2.A2016009.h19v05.006.2016182225713.hdf', 'MOD10A2.A2016009.h20v04.006.2016182230041.hdf', 'MOD10A2.A2016009.h20v05.006.2016182230038.hdf']\n",
      "2016-03-21\n",
      "['MOD10A2.A2016081.h19v04.006.2016110200007.hdf', 'MOD10A2.A2016081.h19v05.006.2016110195736.hdf', 'MOD10A2.A2016081.h20v04.006.2016110200229.hdf', 'MOD10A2.A2016081.h20v05.006.2016110195910.hdf']\n",
      "2016-07-11\n",
      "['MOD10A2.A2016193.h19v04.006.2016202083932.hdf', 'MOD10A2.A2016193.h19v05.006.2016202085128.hdf', 'MOD10A2.A2016193.h20v04.006.2016202083722.hdf', 'MOD10A2.A2016193.h20v05.006.2016202083631.hdf']\n",
      "2015-09-14\n",
      "['MOD10A2.A2015257.h19v04.006.2016181065140.hdf', 'MOD10A2.A2015257.h19v05.006.2016181064608.hdf', 'MOD10A2.A2015257.h20v04.006.2016181070354.hdf', 'MOD10A2.A2015257.h20v05.006.2016181064104.hdf']\n",
      "2015-12-27\n",
      "['MOD10A2.A2015361.h19v04.006.2016183124258.hdf', 'MOD10A2.A2015361.h19v05.006.2016183123821.hdf', 'MOD10A2.A2015361.h20v04.006.2016183124250.hdf', 'MOD10A2.A2015361.h20v05.006.2016183124103.hdf']\n",
      "2016-05-16\n",
      "['MOD10A2.A2016137.h19v04.006.2016147150819.hdf', 'MOD10A2.A2016137.h19v05.006.2016147151208.hdf', 'MOD10A2.A2016137.h20v04.006.2016147144543.hdf', 'MOD10A2.A2016137.h20v05.006.2016147145117.hdf']\n",
      "2016-03-29\n",
      "['MOD10A2.A2016089.h19v04.006.2016110203223.hdf', 'MOD10A2.A2016089.h19v05.006.2016110202008.hdf', 'MOD10A2.A2016089.h20v04.006.2016110205818.hdf', 'MOD10A2.A2016089.h20v05.006.2016110204545.hdf']\n",
      "2016-02-10\n",
      "['MOD10A2.A2016041.h19v04.006.2016050071609.hdf', 'MOD10A2.A2016041.h19v05.006.2016050071329.hdf', 'MOD10A2.A2016041.h20v04.006.2016050072409.hdf', 'MOD10A2.A2016041.h20v05.006.2016050072227.hdf']\n",
      "2015-10-24\n",
      "['MOD10A2.A2015297.h19v04.006.2016182032350.hdf', 'MOD10A2.A2015297.h19v05.006.2016182031829.hdf', 'MOD10A2.A2015297.h20v04.006.2016182032348.hdf', 'MOD10A2.A2015297.h20v05.006.2016182024408.hdf']\n",
      "2015-09-30\n",
      "['MOD10A2.A2015273.h19v04.006.2016181062047.hdf', 'MOD10A2.A2015273.h19v05.006.2016181062026.hdf', 'MOD10A2.A2015273.h20v04.006.2016181062930.hdf', 'MOD10A2.A2015273.h20v05.006.2016181061637.hdf']\n",
      "2015-08-13\n",
      "['MOD10A2.A2015225.h19v04.006.2016181061932.hdf', 'MOD10A2.A2015225.h19v05.006.2016181061952.hdf', 'MOD10A2.A2015225.h20v04.006.2016181061951.hdf', 'MOD10A2.A2015225.h20v05.006.2016181061109.hdf']\n",
      "2016-07-03\n",
      "['MOD10A2.A2016185.h19v04.006.2016194193853.hdf', 'MOD10A2.A2016185.h19v05.006.2016194193610.hdf', 'MOD10A2.A2016185.h20v04.006.2016194194258.hdf', 'MOD10A2.A2016185.h20v05.006.2016194194306.hdf']\n",
      "2016-07-27\n",
      "['MOD10A2.A2016209.h19v04.006.2016222123114.hdf', 'MOD10A2.A2016209.h19v05.006.2016222122928.hdf', 'MOD10A2.A2016209.h20v04.006.2016222123118.hdf', 'MOD10A2.A2016209.h20v05.006.2016222122820.hdf']\n",
      "2015-10-08\n",
      "['MOD10A2.A2015281.h19v04.006.2016181201907.hdf', 'MOD10A2.A2015281.h19v05.006.2016181202801.hdf', 'MOD10A2.A2015281.h20v04.006.2016181201807.hdf', 'MOD10A2.A2015281.h20v05.006.2016181202922.hdf']\n",
      "2016-05-24\n",
      "['MOD10A2.A2016145.h19v04.006.2016155181856.hdf', 'MOD10A2.A2016145.h19v05.006.2016155181506.hdf', 'MOD10A2.A2016145.h20v04.006.2016155181651.hdf', 'MOD10A2.A2016145.h20v05.006.2016155181433.hdf']\n",
      "2015-11-09\n",
      "['MOD10A2.A2015313.h19v04.006.2016182040147.hdf', 'MOD10A2.A2015313.h19v05.006.2016182040153.hdf', 'MOD10A2.A2015313.h20v04.006.2016182033808.hdf', 'MOD10A2.A2015313.h20v05.006.2016182034309.hdf']\n",
      "2016-04-14\n",
      "['MOD10A2.A2016105.h19v04.006.2016114082452.hdf', 'MOD10A2.A2016105.h19v05.006.2016114082255.hdf', 'MOD10A2.A2016105.h20v04.006.2016114075955.hdf', 'MOD10A2.A2016105.h20v05.006.2016114074736.hdf']\n",
      "2015-11-25\n",
      "['MOD10A2.A2015329.h19v04.006.2016182041522.hdf', 'MOD10A2.A2015329.h19v05.006.2016182040439.hdf', 'MOD10A2.A2015329.h20v04.006.2016182043811.hdf', 'MOD10A2.A2015329.h20v05.006.2016182042612.hdf']\n",
      "2016-04-30\n",
      "['MOD10A2.A2016121.h19v04.006.2016130154408.hdf', 'MOD10A2.A2016121.h19v05.006.2016130152344.hdf', 'MOD10A2.A2016121.h20v04.006.2016130151711.hdf', 'MOD10A2.A2016121.h20v05.006.2016130152048.hdf']\n",
      "2015-11-01\n",
      "['MOD10A2.A2015305.h19v04.006.2016182033801.hdf', 'MOD10A2.A2015305.h19v05.006.2016182033426.hdf', 'MOD10A2.A2015305.h20v04.006.2016182034126.hdf', 'MOD10A2.A2015305.h20v05.006.2016182034127.hdf']\n",
      "2016-01-17\n",
      "['MOD10A2.A2016017.h19v04.006.2016026072835.hdf', 'MOD10A2.A2016017.h19v05.006.2016026072809.hdf', 'MOD10A2.A2016017.h20v04.006.2016026072827.hdf', 'MOD10A2.A2016017.h20v05.006.2016026072830.hdf']\n",
      "2016-03-05\n",
      "['MOD10A2.A2016065.h19v04.006.2016110192134.hdf', 'MOD10A2.A2016065.h19v05.006.2016110191744.hdf', 'MOD10A2.A2016065.h20v04.006.2016110192217.hdf', 'MOD10A2.A2016065.h20v05.006.2016110191835.hdf']\n",
      "2016-06-17\n",
      "['MOD10A2.A2016169.h19v04.006.2016184041911.hdf', 'MOD10A2.A2016169.h19v05.006.2016184040300.hdf', 'MOD10A2.A2016169.h20v04.006.2016184041926.hdf', 'MOD10A2.A2016169.h20v05.006.2016184041852.hdf']\n",
      "2015-09-06\n",
      "['MOD10A2.A2015249.h19v04.006.2016181080505.hdf', 'MOD10A2.A2015249.h19v05.006.2016181070522.hdf', 'MOD10A2.A2015249.h20v04.006.2016181070456.hdf', 'MOD10A2.A2015249.h20v05.006.2016181071344.hdf']\n",
      "2015-12-11\n",
      "['MOD10A2.A2015345.h19v04.006.2016182155822.hdf', 'MOD10A2.A2015345.h19v05.006.2016182155815.hdf', 'MOD10A2.A2015345.h20v04.006.2016182160042.hdf', 'MOD10A2.A2015345.h20v05.006.2016182155452.hdf']\n",
      "2016-02-02\n",
      "['MOD10A2.A2016033.h19v04.006.2016043141801.hdf', 'MOD10A2.A2016033.h19v05.006.2016043142308.hdf', 'MOD10A2.A2016033.h20v04.006.2016043141936.hdf', 'MOD10A2.A2016033.h20v05.006.2016043141732.hdf']\n",
      "2015-12-19\n",
      "['MOD10A2.A2015353.h19v04.006.2016182205041.hdf', 'MOD10A2.A2015353.h19v05.006.2016182205255.hdf', 'MOD10A2.A2015353.h20v04.006.2016182204052.hdf', 'MOD10A2.A2015353.h20v05.006.2016182204052.hdf']\n",
      "2016-03-13\n",
      "['MOD10A2.A2016073.h19v04.006.2016110194154.hdf', 'MOD10A2.A2016073.h19v05.006.2016110193845.hdf', 'MOD10A2.A2016073.h20v04.006.2016110194056.hdf', 'MOD10A2.A2016073.h20v05.006.2016110193919.hdf']\n",
      "2015-09-22\n",
      "['MOD10A2.A2015265.h19v04.006.2016181065815.hdf', 'MOD10A2.A2015265.h19v05.006.2016181064618.hdf', 'MOD10A2.A2015265.h20v04.006.2016181072259.hdf', 'MOD10A2.A2015265.h20v05.006.2016181070932.hdf']\n"
     ]
    }
   ],
   "source": [
    "# group by date\n",
    "input_identifiers_per_date = {}\n",
    "\n",
    "for ii in input_identifiers:\n",
    "    \n",
    "    key = ii.split('/')[-1].split('.')[1]\n",
    "    \n",
    "    #print(ii.split('/')[-1].split('.')[1])\n",
    "    \n",
    "    year = int(key[1:5])\n",
    "    days = int(key[5:8])\n",
    "    date_str = datetime.datetime(year, 1, 1) + datetime.timedelta(days - 1)\n",
    "    date_str = date_str.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if date_str in input_identifiers_per_date:\n",
    "        input_identifiers_per_date[date_str].append(ii)\n",
    "    else:\n",
    "        input_identifiers_per_date[date_str] = [ii]\n",
    "        \n",
    "\n",
    "for k in input_identifiers_per_date:\n",
    "    print(k)\n",
    "    \n",
    "    #print(date_str)\n",
    "    \n",
    "    print(input_identifiers_per_date[k])\n",
    "    \n",
    "dates = [dt for dt in input_identifiers_per_date]\n",
    "dates.sort()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mosaicking images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-08-05\n",
      "The mosaic file temp/MOD10A2.A2015217.CentralAsia.tif has been created\n",
      "2015-08-13\n",
      "The mosaic file temp/MOD10A2.A2015225.CentralAsia.tif has been created\n",
      "2015-08-21\n",
      "The mosaic file temp/MOD10A2.A2015233.CentralAsia.tif has been created\n",
      "2015-08-29\n",
      "The mosaic file temp/MOD10A2.A2015241.CentralAsia.tif has been created\n",
      "2015-09-06\n",
      "The mosaic file temp/MOD10A2.A2015249.CentralAsia.tif has been created\n",
      "2015-09-14\n",
      "The mosaic file temp/MOD10A2.A2015257.CentralAsia.tif has been created\n",
      "2015-09-22\n",
      "The mosaic file temp/MOD10A2.A2015265.CentralAsia.tif has been created\n",
      "2015-09-30\n",
      "The mosaic file temp/MOD10A2.A2015273.CentralAsia.tif has been created\n",
      "2015-10-08\n",
      "The mosaic file temp/MOD10A2.A2015281.CentralAsia.tif has been created\n",
      "2015-10-16\n",
      "The mosaic file temp/MOD10A2.A2015289.CentralAsia.tif has been created\n",
      "2015-10-24\n",
      "The mosaic file temp/MOD10A2.A2015297.CentralAsia.tif has been created\n",
      "2015-11-01\n",
      "The mosaic file temp/MOD10A2.A2015305.CentralAsia.tif has been created\n",
      "2015-11-09\n",
      "The mosaic file temp/MOD10A2.A2015313.CentralAsia.tif has been created\n",
      "2015-11-17\n",
      "The mosaic file temp/MOD10A2.A2015321.CentralAsia.tif has been created\n",
      "2015-11-25\n",
      "The mosaic file temp/MOD10A2.A2015329.CentralAsia.tif has been created\n",
      "2015-12-03\n",
      "The mosaic file temp/MOD10A2.A2015337.CentralAsia.tif has been created\n",
      "2015-12-11\n",
      "The mosaic file temp/MOD10A2.A2015345.CentralAsia.tif has been created\n",
      "2015-12-19\n",
      "The mosaic file temp/MOD10A2.A2015353.CentralAsia.tif has been created\n",
      "2015-12-27\n",
      "The mosaic file temp/MOD10A2.A2015361.CentralAsia.tif has been created\n",
      "2016-01-01\n",
      "The mosaic file temp/MOD10A2.A2016001.CentralAsia.tif has been created\n",
      "2016-01-09\n",
      "The mosaic file temp/MOD10A2.A2016009.CentralAsia.tif has been created\n",
      "2016-01-17\n",
      "The mosaic file temp/MOD10A2.A2016017.CentralAsia.tif has been created\n",
      "2016-01-25\n",
      "The mosaic file temp/MOD10A2.A2016025.CentralAsia.tif has been created\n",
      "2016-02-02\n",
      "The mosaic file temp/MOD10A2.A2016033.CentralAsia.tif has been created\n",
      "2016-02-10\n",
      "The mosaic file temp/MOD10A2.A2016041.CentralAsia.tif has been created\n",
      "2016-03-05\n",
      "The mosaic file temp/MOD10A2.A2016065.CentralAsia.tif has been created\n",
      "2016-03-13\n",
      "The mosaic file temp/MOD10A2.A2016073.CentralAsia.tif has been created\n",
      "2016-03-21\n",
      "The mosaic file temp/MOD10A2.A2016081.CentralAsia.tif has been created\n",
      "2016-03-29\n",
      "The mosaic file temp/MOD10A2.A2016089.CentralAsia.tif has been created\n",
      "2016-04-06\n",
      "The mosaic file temp/MOD10A2.A2016097.CentralAsia.tif has been created\n",
      "2016-04-14\n",
      "The mosaic file temp/MOD10A2.A2016105.CentralAsia.tif has been created\n",
      "2016-04-22\n",
      "The mosaic file temp/MOD10A2.A2016113.CentralAsia.tif has been created\n",
      "2016-04-30\n",
      "The mosaic file temp/MOD10A2.A2016121.CentralAsia.tif has been created\n",
      "2016-05-08\n",
      "The mosaic file temp/MOD10A2.A2016129.CentralAsia.tif has been created\n",
      "2016-05-16\n",
      "The mosaic file temp/MOD10A2.A2016137.CentralAsia.tif has been created\n",
      "2016-05-24\n",
      "The mosaic file temp/MOD10A2.A2016145.CentralAsia.tif has been created\n",
      "2016-06-01\n",
      "The mosaic file temp/MOD10A2.A2016153.CentralAsia.tif has been created\n",
      "2016-06-09\n",
      "The mosaic file temp/MOD10A2.A2016161.CentralAsia.tif has been created\n",
      "2016-06-17\n",
      "The mosaic file temp/MOD10A2.A2016169.CentralAsia.tif has been created\n",
      "2016-06-25\n",
      "The mosaic file temp/MOD10A2.A2016177.CentralAsia.tif has been created\n",
      "2016-07-03\n",
      "The mosaic file temp/MOD10A2.A2016185.CentralAsia.tif has been created\n",
      "2016-07-11\n",
      "The mosaic file temp/MOD10A2.A2016193.CentralAsia.tif has been created\n",
      "2016-07-19\n",
      "The mosaic file temp/MOD10A2.A2016201.CentralAsia.tif has been created\n",
      "2016-07-27\n",
      "The mosaic file temp/MOD10A2.A2016209.CentralAsia.tif has been created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mosaic_files = []\n",
    "\n",
    "\n",
    "#for g in input_identifiers_per_date:\n",
    "for g in dates: # use dates instead of input_identifiers_per_date keys in order to be ordered\n",
    "\n",
    "    print(g)\n",
    "    \n",
    "    subset_identifiers = input_identifiers_per_date[g]\n",
    "\n",
    "    list_of_file = [os.path.join(data_path, fn) for fn in subset_identifiers]\n",
    "\n",
    "    #list_of_file[0:4]\n",
    "\n",
    "    mosaicGdal = createMosaicGDAL(list_of_file[0:4], '0 1', 'GTiff')\n",
    "\n",
    "    nstr = list_of_file[0].split('/')[-1]\n",
    "\n",
    "    mosaic_output_file_name = '.'.join([nstr.split('.')[0], nstr.split('.')[1], nameOfRegion['value'], 'tif'])\n",
    "\n",
    "    mosaic_file = os.path.join(temp_folder, mosaic_output_file_name)\n",
    "\n",
    "    mosaicGdal.run(mosaic_file)\n",
    "\n",
    "    mosaic_files.append(mosaic_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp/MOD10A2.A2015217.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015225.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015233.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015241.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015249.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015257.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015265.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015273.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015281.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015289.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015297.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015305.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015313.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015321.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015329.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015337.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015345.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015353.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015361.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016001.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016009.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016017.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016025.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016033.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016041.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016065.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016073.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016081.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016089.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016097.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016105.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016113.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016121.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016129.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016137.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016145.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016153.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016161.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016169.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016177.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016185.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016193.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016201.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016209.CentralAsia.tif']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mosaic_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temp/MOD10A2.A2015217.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015225.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015233.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015241.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015249.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015257.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015265.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015273.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015281.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015289.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015297.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015305.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015313.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015321.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015329.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015337.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015345.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015353.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2015361.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016001.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016009.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016017.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016025.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016033.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016041.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016065.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016073.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016081.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016089.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016097.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016105.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016113.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016121.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016129.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016137.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016145.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016153.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016161.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016169.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016177.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016185.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016193.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016201.CentralAsia.tif',\n",
       " 'temp/MOD10A2.A2016209.CentralAsia.tif']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection, geotransform, no_data_value, data_type = get_metadata(mosaic_files[0])\n",
    "    \n",
    "ml = mosaic_files\n",
    "if load_all_data:\n",
    "    ml = get_matrix_list(mosaic_files)\n",
    "\n",
    "ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count of number of snow days during the season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_ndays = get_snow_ndays(ml)\n",
    "\n",
    "snow_ndays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Count of number of consecutive snow cover days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_max_cons_ndays = get_max_sc_consecutive_ndays(ml)\n",
    "\n",
    "snow_max_cons_ndays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The start day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. compute positions of first snow\n",
    "pos_im, pos_8 = get_start_day_snow_season (ml)\n",
    "\n",
    "# 2. get list of dates from image names\n",
    "py_dates = [datetime.datetime.strptime(d, \"%Y-%m-%d\").date() for d in dates] # dates in datetime format\n",
    "\n",
    "\n",
    "# 3. compute doy of first snow based on 1. and 2.\n",
    "cos_doy_start_day = get_cos_doy_snow_season(py_dates, pos_im, pos_8)\n",
    "\n",
    "cos_doy_start_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The end day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. compute positions of first snow\n",
    "pos_im, pos_8 = get_end_day_snow_season (ml)\n",
    "\n",
    "# 2. get list of dates from image names\n",
    "py_dates = [datetime.datetime.strptime(d, \"%Y-%m-%d\").date() for d in dates] # dates in datetime format\n",
    "\n",
    "# 3. compute doy of first snow based on 1. and 2.\n",
    "cos_doy_end_day = get_cos_doy_snow_season(py_dates, pos_im, pos_8)\n",
    "\n",
    "cos_doy_end_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check result (Count of number of snow days during the season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(snow_ndays)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check result (Count of number of consecutive snow cover days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(snow_max_cons_ndays)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check result (The start day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cos_doy_start_day)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check result (The end day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_results:\n",
    "    \n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(cos_doy_end_day)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write image (Count of number of snow days during the season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snow_ndays_img_name = 'snow_ndays' + '_' + nameOfRegion['value'] + '_' + dates[0] + '_' + dates[-1] + '.tif'\n",
    "snow_ndays_img_name = os.path.join(output_folder, snow_ndays_img_name)\n",
    "\n",
    "write_output_image(snow_ndays_img_name, snow_ndays, 'GTiff', gdal.GDT_UInt16, None, projection, geotransform, no_data_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write image (Count of number of consecutive snow cover days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snow_cons_ndays_img_name = 'snow_cons_ndays' + '_' + nameOfRegion['value'] + '_' + dates[0] + '_' + dates[-1] + '.tif'\n",
    "snow_cons_ndays_img_name = os.path.join(output_folder, snow_cons_ndays_img_name)\n",
    "\n",
    "write_output_image(snow_cons_ndays_img_name, snow_max_cons_ndays, 'GTiff', gdal.GDT_UInt16, None, projection, geotransform, no_data_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write image (The start date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snow_start_date_img_name = 'snow_start_date' + '_' + nameOfRegion['value'] + '_' + dates[0] + '_' + dates[-1] + '.tif'\n",
    "snow_start_date_img_name = os.path.join(output_folder, snow_start_date_img_name)\n",
    "\n",
    "write_output_image(snow_start_date_img_name, cos_doy_start_day, 'GTiff', gdal.GDT_Float32, None, projection, geotransform, -999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Write image (The end date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snow_end_date_img_name = 'snow_end_date' + '_' + nameOfRegion['value'] + '_' + dates[0] + '_' + dates[-1] + '.tif'\n",
    "snow_end_date_img_name = os.path.join(output_folder, snow_end_date_img_name)\n",
    "\n",
    "write_output_image(snow_end_date_img_name, cos_doy_end_day, 'GTiff', gdal.GDT_Float32, None, projection, geotransform, -999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove temporay files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_cfolder(temp_folder)\n",
    "\n",
    "os.rmdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vacc-env2",
   "language": "python",
   "name": "vacc-env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
